{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numpy, pandas, sklearn, pyplot, sqlalchemy \n",
    "import pandas as pd #for dataframe\n",
    "import numpy as np #linear algebra libraries\n",
    "import matplotlib.pyplot as plt #visualization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine # for open connection of SQL and python\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#openning postgre for houseprices table\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "houses = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets copy the file first\n",
    "houses_c = houses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_c[\"is_Pave\"] = pd.get_dummies(houses.street, drop_first=True)\n",
    "houses_c[\"is_AllPub\"] = pd.get_dummies(houses.utilities, drop_first=True)\n",
    "houses_c[\"Y\"] = pd.get_dummies(houses.centralair, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(houses_c[['mszoning', 'lotshape', 'landcontour', 'lotconfig', 'landslope',\n",
    "              'neighborhood', 'condition1', 'condition2', 'bldgtype', 'housestyle', 'roofstyle', 'roofmatl', \n",
    "              'exterior1st', 'exterior2nd', 'masvnrtype', 'exterqual', 'extercond', 'foundation', 'bsmtqual', \n",
    "              'bsmtexposure', 'bsmtfintype1', 'bsmtfintype2', 'heating', 'heatingqc', 'electrical',\n",
    "              'kitchenqual', 'functional', 'garagetype', 'garagefinish', 'garagequal', 'garagecond',\n",
    "              'paveddrive', 'saletype', 'salecondition']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_c = pd.concat([houses_c, dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'mssubclass', 'mszoning', 'lotfrontage', 'lotarea', 'street',\n",
       "       'alley', 'lotshape', 'landcontour', 'utilities',\n",
       "       ...\n",
       "       'saletype_ConLw', 'saletype_New', 'saletype_Oth', 'saletype_WD',\n",
       "       'salecondition_Abnorml', 'salecondition_AdjLand',\n",
       "       'salecondition_Alloca', 'salecondition_Family', 'salecondition_Normal',\n",
       "       'salecondition_Partial'],\n",
       "      dtype='object', length=308)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_c['totrmsabvgrd_overallqual'] = houses_c['totrmsabvgrd'] * houses_c['overallqual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_c = houses_c[[\"saleprice\", \"overallqual\",  \"totrmsabvgrd\", \"bsmtqual_Ex\", \"totrmsabvgrd_overallqual\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.731</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.731</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   991.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 28 Jan 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:10:12</td>     <th>  Log-Likelihood:    </th> <td> -17584.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1460</td>      <th>  AIC:               </th> <td>3.518e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1455</td>      <th>  BIC:               </th> <td>3.520e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                    <td> 7.598e+04</td> <td> 1.78e+04</td> <td>    4.273</td> <td> 0.000</td> <td> 4.11e+04</td> <td> 1.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th>              <td> 4335.2370</td> <td> 2911.903</td> <td>    1.489</td> <td> 0.137</td> <td>-1376.739</td> <td>    1e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totrmsabvgrd</th>             <td>-1.692e+04</td> <td> 2721.020</td> <td>   -6.217</td> <td> 0.000</td> <td>-2.23e+04</td> <td>-1.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bsmtqual_Ex</th>              <td> 5.058e+04</td> <td> 4602.414</td> <td>   10.991</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.96e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totrmsabvgrd_overallqual</th> <td> 4533.2312</td> <td>  422.684</td> <td>   10.725</td> <td> 0.000</td> <td> 3704.096</td> <td> 5362.367</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>288.026</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6310.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.287</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>13.169</td>  <th>  Cond. No.          </th> <td>    757.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.731\n",
       "Model:                            OLS   Adj. R-squared:                  0.731\n",
       "Method:                 Least Squares   F-statistic:                     991.0\n",
       "Date:                Tue, 28 Jan 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:10:12   Log-Likelihood:                -17584.\n",
       "No. Observations:                1460   AIC:                         3.518e+04\n",
       "Df Residuals:                    1455   BIC:                         3.520e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "const                     7.598e+04   1.78e+04      4.273      0.000    4.11e+04    1.11e+05\n",
       "overallqual               4335.2370   2911.903      1.489      0.137   -1376.739       1e+04\n",
       "totrmsabvgrd             -1.692e+04   2721.020     -6.217      0.000   -2.23e+04   -1.16e+04\n",
       "bsmtqual_Ex               5.058e+04   4602.414     10.991      0.000    4.16e+04    5.96e+04\n",
       "totrmsabvgrd_overallqual  4533.2312    422.684     10.725      0.000    3704.096    5362.367\n",
       "==============================================================================\n",
       "Omnibus:                      288.026   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6310.601\n",
       "Skew:                           0.287   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.169   Cond. No.                         757.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y = houses_c['saleprice']\n",
    "\n",
    "\n",
    "X = houses_c[[\"overallqual\",  \"totrmsabvgrd\", \"bsmtqual_Ex\", \"totrmsabvgrd_overallqual\"]]\n",
    "\n",
    "lrm = linear_model.LinearRegression()\n",
    "# fit method estimates the coefficients using OLS\n",
    "lrm.fit(X, Y)\n",
    "\n",
    "# We add a constant to the model as it's a best practice\n",
    "# to do so every time!\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "# We print the summary results\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Accuracy: 0.73 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "#Accuracy:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(lrm, X, Y, cv=5)\n",
    "print(\"OLS Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding best hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "#Validation:\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#making the instance\n",
    "knn = neighbors.KNeighborsRegressor(n_jobs=-1)\n",
    "model = knn\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[5,6,7,8,9,10,11, 15, 18, 20],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=1)\n",
    "#Learning\n",
    "model1.fit(X,Y)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='brute', leaf_size=1, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=8, leaf_size = 1, algorithm = 'brute')\n",
    "knn.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.71 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(knn, X, Y, cv=5)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN R2 score: 0.73 \n"
     ]
    }
   ],
   "source": [
    "print(\"KNN R2 score: %0.2f \" % knn.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS:\n",
    "- Mean accuracy is higher for OLS than KNN, variance looks same for both, and R2 for both is same.\n",
    "- Only looking at mean accuracy, I will choose OLS over KNN, also because OLS is great for bigger data than KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
